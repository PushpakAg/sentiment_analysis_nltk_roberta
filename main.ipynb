{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "plt.style.use(\"ggplot\")\n",
    "# import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C://Users/pushp/Downloads/amazon_review/Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(100000)\n",
    "df[\"Score\"].value_counts().sort_index().plot(kind = \"bar\", title = \"Count of reviews\", color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = df[\"Text\"][51]\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkns = nltk.word_tokenize(ex)\n",
    "print(tkns[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos_tag = nltk.pos_tag(tkns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('maxent_ne_chunker')  # Download the named entity chunker model\n",
    "nltk.download('words')\n",
    "ent = nltk.chunk.ne_chunk(pos_tag)\n",
    "ent.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "pl_Score = sia.polarity_scores(ex)\n",
    "print(pl_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in range(len(df[\"Text\"])):\n",
    "    text = df[\"Text\"][i]\n",
    "    myId = df[\"Id\"][i]\n",
    "    res[myId] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns = {\"index\" : \"Id\"})\n",
    "vaders = vaders.merge(df, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score vs vader_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize = (15,3))\n",
    "plot = sns.barplot(data = vaders, x= \"Score\", y= \"neg\",ax = axs[0])\n",
    "plot = sns.barplot(data = vaders, x= \"Score\", y= \"neu\",ax = axs[1])\n",
    "plot = sns.barplot(data = vaders, x= \"Score\", y= \"pos\",ax = axs[2])\n",
    "axs[0].set_title(\"neg Score\")\n",
    "axs[1].set_title(\"neu Score\")\n",
    "axs[2].set_title(\"pos Score\")\n",
    "# plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_score_roberta(example):\n",
    "    enc_text = tokenizer(example, return_tensors = \"pt\")\n",
    "    output = model(**enc_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict =  {\n",
    "        \"roberta_neg\" : scores[0],\n",
    "        \"roberta_neu\" : scores[1],\n",
    "        \"roberta_pos\" : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = res[1].keys()\n",
    "print(list(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting prob scores for all 1000 text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in range(1000):\n",
    "    try:\n",
    "        text = df[\"Text\"][i]\n",
    "        myId = df[\"Id\"][i]\n",
    "        v_res = sia.polarity_scores(text)\n",
    "        v_res_rename = {}\n",
    "        for key,value in v_res.items():\n",
    "            v_res_rename[f\"vader_{key}\"] = value\n",
    "        roberta_res = polarity_score_roberta(text)\n",
    "        both_res = {**v_res_rename, **roberta_res}\n",
    "        res[myId] = both_res    \n",
    "    except RuntimeError:\n",
    "        print(f\"broke for id {myId}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns = {\"index\" : \"Id\"})\n",
    "results_df = results_df.merge(df, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulaizing results from both vader and roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = results_df, vars =[ 'vader_neg', 'vader_neu', 'vader_pos',\n",
    "                                        'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
    "                                        hue = \"Score\",\n",
    "                                        palette= \"tab10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query(\"Score == 5\") \\\n",
    "      .sort_values(\"roberta_pos\",ascending=False)[\"Text\"].values[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"C://Users/pushp/roberta_model\"\n",
    "\n",
    "# Save the tokenizer and model\n",
    "tokenizer.save_pretrained(model_directory)\n",
    "model.save_pretrained(model_directory)\n",
    "\n",
    "# Optionally, you can also save the model configuration\n",
    "model.config.save_pretrained(model_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyAI3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
